// Load environment variables FIRST (before any other imports)
import "./env.js"

import express from "express"
import { createServer } from "http"
import { Server } from "socket.io"
import { ObjectId } from "mongodb"
import cors from "cors"
import healthRouter from "./routes/health.js"
import jobsRouter, { setSocketIo } from "./routes/jobs.js"
import toolsRouter from "./routes/tools.js"
import { socketAuthMiddleware, verifyWorkspaceAccess } from "./lib/auth.js"
import { resumeInProgressJobs } from "./lib/indexing-processor.js"
import { getIndexJobsCollection } from "./lib/db.js"
import logger from "./lib/logger.js"

const PORT = process.env.PORT || 3001
const WEB_APP_URL = process.env.WEB_APP_URL || "http://localhost:3000"

logger.info("ðŸš€ Starting Indexer Service...")
logger.info(`ðŸ“‹ Configuration:`)
logger.info(`   - Port: ${PORT}`)
logger.info(`   - Web App URL: ${WEB_APP_URL}`)
logger.info(`   - MongoDB: ${process.env.MONGODB_URI?.split("@")[1]?.split("/")[0] || "connected"}`)
logger.info(`   - Node: ${process.version}`)

// Create Express app
const app = express()

// Request logging middleware
app.use((req, res, next) => {
  const start = Date.now()
  res.on("finish", () => {
    const duration = Date.now() - start
    logger.api(req.method, req.path, res.statusCode, duration)
  })
  next()
})

// Middleware
app.use(express.json({ limit: "100mb" })) // Support large PDF uploads
logger.info("ðŸ“¦ Body parser: 100MB limit")

app.use(
  cors({
    origin: WEB_APP_URL,
    credentials: true,
  })
)
logger.info(`ðŸ”’ CORS enabled for: ${WEB_APP_URL}`)

// Routes
app.use(healthRouter)
app.use(jobsRouter)
app.use("/tools", toolsRouter)
logger.info("ðŸ“ Routes registered: /health, /jobs/start, /tools/searchPages, /tools/getPage")

// Create HTTP server
const httpServer = createServer(app)

// Create Socket.io server
const io = new Server(httpServer, {
  cors: {
    origin: WEB_APP_URL,
    credentials: true,
  },
})

// Pass Socket.io instance to routes
setSocketIo(io)

// Socket.io authentication middleware
io.use(socketAuthMiddleware)

// Socket.io connection handling
io.on("connection", (socket) => {
  const userId = socket.data.userId
  logger.socket(`âœ… User connected: ${userId} (socket: ${socket.id})`)

  // Handle workspace room join
  socket.on("workspace:join", async ({ workspaceId }) => {
    logger.socket(`ðŸ“¥ Join request: workspace=${workspaceId}, user=${userId}`)
    
    try {
      // Verify user has access to workspace
      const hasAccess = await verifyWorkspaceAccess(workspaceId, userId)

      if (!hasAccess) {
        logger.warn(`ðŸš« Access denied: user=${userId}, workspace=${workspaceId}`)
        socket.emit("error", { message: "Access denied to workspace" })
        return
      }

      // Join workspace room
      socket.join(`workspace:${workspaceId}`)
      const roomSize = io.sockets.adapter.rooms.get(`workspace:${workspaceId}`)?.size || 0
      logger.socket(
        `âœ… User joined room: user=${userId}, workspace=${workspaceId}, roomSize=${roomSize}`
      )

      // Confirm join
      socket.emit("workspace:joined", { workspaceId })

      // Check for active indexing job and send current state
      const indexJobs = await getIndexJobsCollection()
      const activeJob = await indexJobs.findOne({ 
        workspaceId: new ObjectId(workspaceId),
        status: "in-progress"
      })

      if (activeJob) {
        logger.socket(`ðŸ“¤ Sending current job state to newly joined user`)
        
        // Determine appropriate message based on progress
        let message = "Resuming indexing..."
        if (activeJob.progress.analyzedPages > 0 && activeJob.progress.analyzedPages < activeJob.progress.totalPages) {
          message = `Analyzing document... (${activeJob.progress.analyzedPages}/${activeJob.progress.totalPages} pages)`
        } else if (activeJob.progress.processedPages > 0 && activeJob.progress.processedPages < activeJob.progress.totalPages) {
          message = `Parsing document... (${activeJob.progress.processedPages}/${activeJob.progress.totalPages} pages)`
        }
        
        // Send current progress immediately to this socket
        socket.emit("index:progress", {
          workspaceId,
          phase: "processing",
          totalDocuments: activeJob.progress.totalDocuments,
          processedDocuments: activeJob.progress.processedDocuments,
          totalPages: activeJob.progress.totalPages,
          processedPages: activeJob.progress.processedPages,
          analyzedPages: activeJob.progress.analyzedPages,
          message,
        })
      }
    } catch (error) {
      logger.error("âŒ Error joining workspace:", error)
      socket.emit("error", { message: "Failed to join workspace" })
    }
  })

  // Handle workspace room leave
  socket.on("workspace:leave", ({ workspaceId }) => {
    socket.leave(`workspace:${workspaceId}`)
    logger.socket(`ðŸ‘‹ User left room: user=${userId}, workspace=${workspaceId}`)
  })

  // Handle index start request
  socket.on("index:start", async ({ workspaceId, documentIds, params }) => {
    logger.socket(`ðŸ“‹ Index start request: workspace=${workspaceId}, user=${userId}`)
    
    try {
      // Verify user has access to workspace (already verified in join, but double-check)
      const hasAccess = await verifyWorkspaceAccess(workspaceId, userId)

      if (!hasAccess) {
        logger.warn(`ðŸš« Access denied for index: user=${userId}, workspace=${workspaceId}`)
        socket.emit("error", { message: "Access denied to workspace" })
        return
      }

      // Import startIndexingJob dynamically to avoid circular dependency
      const { startIndexingJob } = await import("./lib/indexing-processor.js")
      
      // Start indexing job
      startIndexingJob(workspaceId, io, {
        documentIds,
        renderDpi: params?.renderDpi,
        renderQuality: params?.renderQuality,
        analysisModel: params?.analysisModel,
        analysisDetail: params?.analysisDetail,
      }).catch((error) => {
        logger.error(`âŒ Indexing job failed for workspace ${workspaceId}:`, error)
      })

      // Confirm start
      socket.emit("index:started", { workspaceId })
      logger.socket(`âœ… Index started: workspace=${workspaceId}`)
    } catch (error: any) {
      logger.error("âŒ Error starting index:", error)
      socket.emit("error", { message: error.message || "Failed to start indexing" })
    }
  })

  // Handle disconnect
  socket.on("disconnect", () => {
    logger.socket(`âŒ User disconnected: ${userId} (socket: ${socket.id})`)
  })
})

// Export io for use in other modules
export { io }

// Start server
httpServer.listen(PORT, () => {
  logger.success(`ðŸŽ‰ Indexer Service ready!`)
  logger.success(`ðŸŒ HTTP Server: http://localhost:${PORT}`)
  logger.success(`âš¡ Socket.io Server: ws://localhost:${PORT}`)
  logger.info(`ðŸ“¡ Waiting for connections...`)
  logger.info("")

  // Resume any in-progress jobs
  resumeInProgressJobs(io).catch((error) => {
    logger.error(`Failed to resume jobs: ${error.message}`)
  })
})

// Graceful shutdown
async function gracefulShutdown(signal: string) {
  logger.info(`\n${signal} received, shutting down gracefully...`)
  
  // Close HTTP server
  httpServer.close(() => {
    logger.info("HTTP server closed")
  })

  // Close Socket.io connections
  io.close(() => {
    logger.info("Socket.io server closed")
  })

  // Close MongoDB connection
  const { closeDatabase } = await import("./lib/db")
  await closeDatabase()

  logger.info("Shutdown complete")
  process.exit(0)
}

// Handle shutdown signals
process.on("SIGTERM", () => gracefulShutdown("SIGTERM"))
process.on("SIGINT", () => gracefulShutdown("SIGINT"))

// Handle uncaught errors
process.on("uncaughtException", (error) => {
  logger.error("Uncaught Exception:", error)
  gracefulShutdown("UNCAUGHT_EXCEPTION")
})

process.on("unhandledRejection", (reason, promise) => {
  logger.error("Unhandled Rejection at:", promise, "reason:", reason)
  gracefulShutdown("UNHANDLED_REJECTION")
})

